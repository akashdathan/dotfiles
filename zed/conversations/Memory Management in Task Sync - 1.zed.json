{"id":"569865d3-a288-41de-b6cf-2113b1ed5868","zed":"context","version":"0.4.0","text":"\n\n\n```ts atom-web/src/server/new-structure/application/use-cases/tasks/sync-tasks/use-case.ts\nimport { Review } from \"@atom/types\";\nimport { inject, injectable } from \"inversify\";\n\nimport pLimit from \"p-limit\";\nimport getRedisClient from \"../../../../../config/redis\";\nimport { UnauthorizedError } from \"../../../../../utils/errors\";\nimport logger from \"../../../../../utils/loggers/logger\";\nimport { IDocumentRepo } from \"../../../../domain/document/repos/document.repo\";\nimport { ERequestInstanceStatusType } from \"../../../../domain/request/instance/entities/request-instance-status-type.entity\";\nimport { RequestApprovalDocumentTaskService } from \"../../../../domain/task/services/request-approval-document-task/request-approval-document-task.service\";\nimport { RespondRequestTaskService } from \"../../../../domain/task/services/respond-request-task/respond-request-task.service\";\nimport { ReviewDocumentTask } from \"../../../../domain/task/services/review-task-manager/review-document-task.service\";\nimport { ReviewRequestTask } from \"../../../../domain/task/services/review-task-manager/review-request-task.service\";\nimport { AuthzService } from \"../../../../framework/application/authz.service\";\nimport { BaseUseCase } from \"../../../../framework/application/use-case\";\nimport container from \"../../../../framework/inversify/inversify.config\";\nimport TYPES from \"../../../../framework/inversify/types\";\nimport { RequestInstanceRepo } from \"../../../repositories/request-instance.repo\";\nimport { ReviewFlowServiceACL } from \"../../../services/review-flow-acl.service\";\n\ntype TaskSyncOperation = {\n  status: \"not_started\" | \"in_progress\" | \"completed\" | \"failed\";\n  timestamp: number;\n  processed: (\n    | {\n        flowID: number;\n      }\n    | {\n        documentID: number;\n      }\n    | {\n        requestID: number;\n      }\n  )[];\n  processedWithError: ({\n    timestamp: number;\n    error: string;\n  } & ({ flowID: number } | { documentID: number } | { requestID: number }))[];\n  pendingOperations: (\n    | {\n        flowID: number;\n      }\n    | {\n        documentID: number;\n      }\n    | {\n        requestID: number;\n      }\n  )[];\n  processedPerSecond?: number;\n};\n\nconst redisClient = getRedisClient();\n\n@injectable()\nexport class UseCase implements BaseUseCase<void, Promise<any>> {\n  constructor(\n    @inject(ReviewFlowServiceACL) private readonly reviewFlowServiceACL: ReviewFlowServiceACL,\n    @inject(ReviewDocumentTask) private readonly reviewDocumentTask: ReviewDocumentTask,\n    @inject(ReviewRequestTask) private readonly requestReviewTask: ReviewRequestTask,\n    @inject(TYPES.RequestApprovalDocumentTaskService)\n    private readonly requestApprovalDocumentTaskService: RequestApprovalDocumentTaskService,\n    @inject(TYPES.RespondRequestTaskService) private readonly respondRequestTaskService: RespondRequestTaskService,\n    @inject(AuthzService) private readonly authzService: AuthzService,\n    @inject(TYPES.IDocumentRepo) private readonly documentRepo: IDocumentRepo,\n    @inject(RequestInstanceRepo) private readonly requestInstanceRepo: RequestInstanceRepo\n  ) {}\n\n  public async execute() {\n    if (!this.authzService.isUserAdmin()) throw new UnauthorizedError(\"Only admins can start task sync\");\n\n    const taskSync = await this.readTaskSync();\n\n    if (\n      taskSync.status === \"completed\" ||\n      (taskSync.status === \"in_progress\" && taskSync.timestamp > Date.now() - 1000 * 30)\n    ) {\n      // If last update was less than 30 seconds ago, return the current status\n      return this.getResult(taskSync);\n    }\n\n    // If last update was more than 30 seconds ago, start processing again\n    try {\n      if (taskSync.status === \"not_started\") {\n        const pendingOperations = [];\n\n        let documentIDs = await this.documentRepo.getUnreviewedDocumentIDs();\n\n        for (const documentID of documentIDs) {\n          pendingOperations.push({\n            documentID,\n          });\n        }\n\n        documentIDs = [];\n\n        let requestIDs = await this.requestInstanceRepo.getOpenIDs();\n\n        for (const requestID of requestIDs) {\n          pendingOperations.push({\n            requestID,\n          });\n        }\n\n        requestIDs = [];\n\n        let reviewFlows = await this.reviewFlowServiceACL.getAllReviewFlowsForSubjects({\n          subjects: [Review.Subject.REQUEST, Review.Subject.DOCUMENT_REVISION],\n        });\n\n        for (const flow of reviewFlows) {\n          pendingOperations.push({\n            flowID: flow.id,\n          });\n        }\n\n        reviewFlows = [];\n\n        await this.updateTaskSync({\n          status: \"in_progress\",\n          processed: taskSync.processed,\n          pendingOperations,\n          timestamp: Date.now(),\n          processedWithError: taskSync.processedWithError,\n        });\n      }\n\n      this.startProcessing();\n\n      return this.getResult(taskSync);\n    } catch (error) {\n      await this.updateTaskSync({\n        status: \"failed\",\n        processed: taskSync.processed,\n        pendingOperations: taskSync.pendingOperations,\n        timestamp: Date.now(),\n        processedWithError: taskSync.processedWithError,\n      });\n\n      throw error;\n    }\n  }\n\n  private getResult(taskSync: TaskSyncOperation) {\n    const processedWithErrorCount = taskSync.processedWithError.length;\n    const processedCount = taskSync.processed.length + processedWithErrorCount;\n    const pendingCount = taskSync.pendingOperations.length;\n    const totalCount = processedCount + pendingCount;\n\n    const processedPercentage = (processedCount / totalCount) * 100;\n    const roundedProcessedPercentage = Math.round(processedPercentage * 100) / 100;\n\n    return {\n      status: taskSync.status,\n      completedPercentage: roundedProcessedPercentage + \"%\",\n      processedCount: processedCount,\n      totalCount,\n      processingSpeed: taskSync.processedPerSecond + \" operations/s\",\n      secondsSinceLastUpdate: Math.floor((Date.now() - taskSync.timestamp) / 1000),\n      erroredCount: processedWithErrorCount,\n      errored: taskSync.processedWithError,\n    };\n  }\n\n  private async startProcessing() {\n    const { pendingOperations, processed, processedWithError } = await this.readTaskSync();\n    const limit = pLimit(5);\n    const newPendingOperations = new Set(pendingOperations);\n    const newProcessed = processed;\n    const newProcessedWithError = processedWithError;\n\n    let processedCount = 0;\n    let startTime = Date.now();\n\n    this.updateTaskSync({\n      status: \"in_progress\",\n      processed: newProcessed,\n      pendingOperations,\n      timestamp: Date.now(),\n      processedWithError: newProcessedWithError,\n    });\n\n    const updateInterval = setInterval(() => {\n      const elapsedTime = Date.now() - startTime;\n      const elapsedSeconds = Math.floor(elapsedTime / 1000);\n\n      const processedPerSecond = processedCount / elapsedSeconds;\n\n      processedCount = 0;\n      startTime = Date.now();\n\n      this.updateTaskSync({\n        status: \"in_progress\",\n        processed: newProcessed,\n        pendingOperations: Array.from(newPendingOperations),\n        timestamp: Date.now(),\n        processedWithError: newProcessedWithError,\n        processedPerSecond,\n      });\n\n      if (newPendingOperations.size === 0) {\n        clearInterval(updateInterval);\n        this.updateTaskSync({\n          status: \"completed\",\n          processed: newProcessed,\n          pendingOperations: Array.from(newPendingOperations),\n          timestamp: Date.now(),\n          processedWithError: newProcessedWithError,\n          processedPerSecond,\n        });\n      }\n    }, 10000);\n\n    pendingOperations.forEach((pendingOperation) => {\n      limit(async () => {\n        try {\n          if (\"flowID\" in pendingOperation) {\n            await this.processReviewFlowOperations(pendingOperation);\n          } else if (\"documentID\" in pendingOperation) {\n            await this.processDocumentOperations(pendingOperation);\n          } else if (\"requestID\" in pendingOperation) {\n            await this.processRequestOperations(pendingOperation);\n          }\n\n          newPendingOperations.add(pendingOperation);\n          newProcessed.push(pendingOperation);\n        } catch (error: any) {\n          console.error(\"Error processing operation\", error);\n          newProcessedWithError.push({\n            ...pendingOperation,\n            timestamp: Date.now(),\n            error: \"message\" in error ? error.message : \"Unknown error\",\n          });\n        } finally {\n          processedCount++;\n          newPendingOperations.delete(pendingOperation);\n        }\n      });\n    });\n  }\n\n  private async processReviewFlowOperations({ flowID }: { flowID: number }) {\n    const flow = await this.reviewFlowServiceACL.getReviewFlowByID(flowID);\n\n    if (flow.status === Review.Status.PENDING) {\n      if (flow.subjectType === Review.Subject.REQUEST) {\n        await this.requestReviewTask.saveTasks(flow);\n      } else if (flow.subjectType === Review.Subject.DOCUMENT_REVISION) {\n        await this.reviewDocumentTask.saveTasks(flow);\n      }\n    }\n  }\n\n  private async processDocumentOperations({ documentID }: { documentID: number }) {\n    const document = await this.documentRepo.getByID(documentID);\n\n    await this.requestApprovalDocumentTaskService.saveTasks(document);\n  }\n\n  private async processRequestOperations({ requestID }: { requestID: number }) {\n    const request = await this.requestInstanceRepo.getByID(requestID);\n    if (request && request.currentStatusType === ERequestInstanceStatusType.OPEN) {\n      await this.respondRequestTaskService.saveTasks(request);\n    }\n  }\n\n  private updateTaskSync(taskSync: TaskSyncOperation) {\n    logger.info(\"Updating task sync status\", taskSync);\n\n    if (taskSync.status === \"completed\") {\n      logger.info(\"Task sync completed\");\n    }\n\n    return redisClient.set(\"task_sync\", JSON.stringify(taskSync));\n  }\n\n  private async readTaskSync(): Promise<TaskSyncOperation> {\n    const taskSyncStr = await redisClient.get(\"task_sync\");\n\n    try {\n      if (taskSyncStr === null) throw new Error(\"Task sync not started\");\n      return JSON.parse(taskSyncStr as any) as TaskSyncOperation;\n    } catch (_) {\n      return {\n        status: \"not_started\",\n        processed: [],\n        pendingOperations: [],\n        timestamp: Date.now(),\n        processedWithError: [],\n      };\n    }\n  }\n}\n\ncontainer.bind<UseCase>(UseCase).toSelf();\n```\n\nhelp me understand why the let arrays has to be reset to empty array\nIn the code, there are three instances where arrays are reset to empty:\n\n```typescript\ndocumentIDs = [];\nrequestIDs = [];\nreviewFlows = [];\n```\n\nThese arrays are reset to empty after their data has been processed and added to the `pendingOperations` array. Here's why this is done:\n\n1. **Memory Management**: By setting these arrays to empty after using their data, it helps free up memory. The original arrays are no longer needed since their contents have been transferred to `pendingOperations`.\n\n2. **Garbage Collection**: This practice allows the JavaScript garbage collector to reclaim the memory that was used by these potentially large arrays of IDs and review flows, as they're no longer referenced anywhere in the code.\n\nFor example, with `documentIDs`:\n```typescript\nlet documentIDs = await this.documentRepo.getUnreviewedDocumentIDs();\nfor (const documentID of documentIDs) {\n  pendingOperations.push({\n    documentID,\n  });\n}\ndocumentIDs = []; // Clear the array since we don't need it anymore\n```\n\nThis is particularly important in this context because:\n- These arrays could potentially be large (many documents, requests, or review flows)\n- The data is already stored in the `pendingOperations` array\n- The sync operation might run for a while, so keeping unnecessary data in memory isn't efficient\n\nIt's a memory optimization technique, though in modern JavaScript with good garbage collection, its impact might be minimal unless dealing with very large datasets.\nksjdf\n\nI noticed you typed random characters. If you have a specific question or need assistance, please feel free to ask it clearly, and I'll be happy to help you!\nbut wont the garbade collector run after the function call is done?\nYes, you're absolutely right! When the function scope ends, any variables declared within it will automatically become eligible for garbage collection if there are no remaining references to them. So in this case, explicitly setting `documentIDs = []`, `requestIDs = []`, and `reviewFlows = []` is unnecessary.\n\nThe code could be simplified by removing these manual array clearing operations:\n\n```typescript\nlet documentIDs = await this.documentRepo.getUnreviewedDocumentIDs();\nfor (const documentID of documentIDs) {\n  pendingOperations.push({\n    documentID,\n  });\n}\n// documentIDs = []; <- This line isn't needed\n\nlet requestIDs = await this.requestInstanceRepo.getOpenIDs();\nfor (const requestID of requestIDs) {\n  pendingOperations.push({\n    requestID,\n  });\n}\n// requestIDs = []; <- This line isn't needed\n\nlet reviewFlows = await this.reviewFlowServiceACL.getAllReviewFlowsForSubjects({\n  subjects: [Review.Subject.REQUEST, Review.Subject.DOCUMENT_REVISION],\n});\nfor (const flow of reviewFlows) {\n  pendingOperations.push({\n    flowID: flow.id,\n  });\n}\n// reviewFlows = []; <- This line isn't needed\n```\n\nThe JavaScript engine's garbage collector will handle cleaning up these arrays once they go out of scope. This appears to be a case of premature optimization that doesn't provide any real benefit.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":227}}},{"id":{"replica_id":0,"value":28},"start":10426,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":228}}},{"id":{"replica_id":0,"value":29},"start":11906,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":229}}},{"id":{"replica_id":0,"value":80},"start":11913,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":230}}},{"id":{"replica_id":0,"value":81},"start":12071,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":231}}},{"id":{"replica_id":0,"value":168},"start":12139,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":232}}},{"id":{"replica_id":0,"value":169},"start":13449,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":233}}}],"summary":"Memory Management in Task Sync","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null},{"range":{"start":3,"end":10356},"icon":"File","label":"atom-web/src/server/new-structure/application/use-cases/tasks/sync-tasks/use-case.ts","metadata":{"path":"atom-web/src/server/new-structure/application/use-cases/tasks/sync-tasks/use-case.ts"}}],"thought_process_output_sections":[]}